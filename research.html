<HTML>
<HEAD>
<TITLE>Ryota NISHIMURA's Web Page</TITLE>
</HEAD>

<BODY>
<center>

<table width="90%" border="0">
<tr><td>
<H2>研究内容 </H2>
<hr>

人間とシステムとの間で対話自体を楽しむことが出来るような自然な対話システムの実現を目指しています．システムの例として，現在動作しているものを以下に紹介します．<BR>
<BR>
<center><object width="425" height="344"><param name="movie" value="http://www.youtube.com/v/AWiMZRwcJAw&hl=ja&fs=1&"></param><param name="allowFullScreen" value="true"></param><param name="allowscriptaccess" value="always"></param><embed src="http://www.youtube.com/v/AWiMZRwcJAw&hl=ja&fs=1&" type="application/x-shockwave-flash" allowscriptaccess="always" allowfullscreen="true" width="425" height="344"></embed></object><BR>
動画１：システムの動作例</center><BR>
<BR>
システムの概略図を以下に示します．<BR>
<center><img width="600" src="./img/system.gif"><BR>
図１：システムの概略図</center><BR>
<BR>
システムの特徴としては，以下の事柄があります．<BR>
<BR>
<B>（１）リアルタイムに応答タイミングを検出し，種々の雑談現象を扱い応答する</B><BR>
タイミングの検出と応答の種類の決定には決定木を用いている．決定木は，応答を返すか否かを逐次的(100ms間隔)に判定しており，応答する場合には，"あいづち"，"復唱"や"情報提供"などの応答現象の中から，どの応答が適切かを判断し決定する．この決定木の学習には，実際の人間同士の対話を収録したデータ（コーパス）を用いている．また，学習に用いる素性としては，音声のピッチ(高さ)・パワー（大きさ）の傾きや，ユーザの発話長，ポーズ長などの韻律情報を利用している． <BR>
<BR>
<B>（２）応答を出力する際の韻律情報は，ユーザに同調を示すように制御する</B><BR>
韻律制御については，人間同士の対話中の両話者の韻律変化について調査・分析した．その結果，変化の仕方と対話の盛り上がりに相関があることが分かった為，これをモデル化しシステムに実装した．このモデルにより，応答音声の韻律をユーザに同調させることで，ユーザに対して同調性を示し，対話がより円滑に進むようにしている．<BR>
<BR>
<B>（３）その他の雑談現象への対応</B><BR>
この対話システムは，ユーザとシステムの混合主導で対話を進めることができる．また，システムは，応答するべきタイミングであるかを逐次的に監視しており，このことからオーバーラップした応答も返すことが可能になっている．また，ユーザからシステムへの割り込み発話（バージイン）も扱っている．<BR>
<BR>
<BR>
<H2>今後のアイディア </H2>
<HR>
<B>・場の空気を読む手法の導入</B><BR>
対話中に得られる情報として，音声からの特徴や言語的な特徴の他に，画像やその他センサからの情報を元に，場の状況を捉え，その場に応じた対応を行う．これに関して，受入研究室では，言語情報と画像情報を用いて，タスク推定を行う研究が始まっている．タスクの推定は，システムがタスクの切り替えを行う場合や，ユーザに対し適切な対応を行う上で必須であり，これを用いて対話システムでのタスク制御を行うことができれば，頑健な対話を行うことができると期待される．また，雑談対話制御を行う場合や，主導権制御を行う場合にも，場の空気を読み，状況を把握することは非常に重要である．<BR>
この研究項目は，今後確実に発展していくであろうユビキタス社会において，威力を発揮することが期待でき，それに先駆けて研究・開発を行うことは有意義である．<BR>
<BR>
<B>・画面表示・エージェントの作成，個性の追加</B><BR>
現在の対話システムでは，対話を行うのみで，キャラクタなどが表示されるということが無い．また，情報を提示する際には，音声による出力のみである為，画面表示などを行うことによって，より頑健に情報の伝達が行えるものと考えられる．表示するエージェントについても，「リアルな人間の顔」「愛嬌のあるキャラクタ」などによって違いが現れると予想されることから，これらの視覚的効果の調査・分析を行う．<BR>
また，エージェントの個性・性格などを変化させることによって，ユーザにどのような印象を与えるかについても調査・分析する．<BR>
<BR>
<B>・2人のエージェントとユーザの3人対話</B><BR>
現在はユーザ対システムの1対1対話であるが，これを，"性格の異なる２つのエージェント(システム)とユーザとの3人対話"に拡張する．エージェント間では，実際に発話した内容以外にも，すべての情報が共有できる為，様々な対話制御が可能となり，広い応用が考えられる．例えば，あるエージェントはユーザに賛同し，一方のエージェントは反論するという対話を実現すれば，対話を盛り上げることができる．<BR>
また，各エージェントの個性の差別化を図り，その違いによってユーザにどのような影響を与えるかについて，調査・分析を行う．エージェントの表示方法の違いとしては，「ロボットを用いる」「2つの画面に個別に表示する」「1つの画面に2つのエージェントを表示する」といったことが考えられる．また，エージェント間の上下関係や，ユーザ専属のエージェント，エキスパートエージェントなど知識の差別化も図る．応答タイミングや，各種応答の頻度などもエージェント毎に設け，受ける印象の違いを明らかにする．<BR>
<BR>
<B>・対話の主導権による制御</B><BR>
　現在のシステムでの応答タイミング・応答種類決定モデルと韻律制御モデルは，主導権がどちらにあるかという点は考慮されていない．しかし，実際の対話においては，主導権が大きな役割を果し，対話の主導権をどちらが持っているかということと，応答タイミング／韻律制御には関連があると思われる．この点において調査分析し，対話の主導権とモデルの対応を検証する必要がある．人間同士の対話において，主導権を持っている側とそうでない側で，どのように対話を行っているかを調査・分析し，それぞれの場合について，個別にモデルを学習することによって，主導権がある場合と無い場合とのそれぞれに対応することができる．<BR>
　しかし，実際にこれをシステムに実装する場合には，主導権がユーザとシステムのどちらにあるのかを推定してモデルを切り替える必要がある．この主導権推定機構をシステムに導入する必要がある．また，主導権自体を切り替える手法の導入も必要であり，これには，主導権切り替えモデルの導入か，または主導権を制御する応答の導入が必要になる．<BR>
<BR>
<B>・知らないふり</B><BR>
システムがユーザの言ったことに対して"知らないふり"をして応答することを考える．これには，当然ユーザの言ったことを正確に把握し，その上で知らないふりをするという必要がある．知らないふりが出来るようになると，システム側から対話を制御することも可能になり，より発展した対話を実現することが可能になると期待できる．例えば，以下のような対話が考えられる．<BR>
<BR>
ユーザ：「豊橋-東京間ってどれくらいの距離かなぁ？」<BR>
システム：「どれくらいですかね？」<BR>
ユーザ：「200kmぐらいかなぁ〜．」<BR>
システム：「もっと遠いと思うよ．」（実際は300km程度という情報を持っている）<BR>
<BR>
ユーザからある情報について問われた場合，システムがその情報を持っている場合でも，すぐには提示せず，「どれくらいですかね？(システム発話)」などと知らないふりをする．このことで，ユーザからの発話を促す．また，ユーザが具体的な数値を答えた場合においては，システムは，実際に持っている知識との比較を行い「もっと遠いと思うよ．」（実際は300km程度）と対話を続けることもできる．このように対話をより楽しむことができる環境の実現が期待される．この機能を取り入れた対話システムは存在しない．<BR>
<BR>
<B>・雑談対話制御</B><BR>
現在のシステムは，タスクや語彙も小さく，一般の雑談ができるというものではない．また，雑談を行う際には，発話スタイルの崩れや，発声の怠けなどが加わり，音声認識も難しくなる．その為に，対話の流れや音声認識精度に対して，より頑健な対話戦略をたて，より広く雑談ができるような対話制御（"雑談対話制御"）を行う．現在の対話システムでは，対話制御としては，スロットフィリングを用いてユーザ発話から必要な情報を収集し，ユーザ発話とマッチするテンプレートを用いて，収集した情報を元に応答として返すという単純なものになっており，この機構の見直しや，テンプレートの雑談対話に対する強化などが必要になる．<BR>
また，雑談対話制御の為には，タスク制御や主導権制御などを行う必要がある．主導権制御には，上述した「知らないふり」などが有効に働くものと思われる．また，タスク制御には，「場の空気を読む手法」などが有効に働くものと思われる．<BR>
<BR>
<B>・視線追跡による対話焦点の分析</B><BR>
人間が対話をする際に，音声以外の情報として，視覚的な情報を用いていると考えられる．これに対しては，上述のように，エージェントやその他の情報のディスプレイへの表示を考えている．その際に，システムを使用するユーザの視線の状態を観察し，どのような情報に注目しているか，どのような情報を欲しているかを調査・分析する．また，ディスプレイ上のどこに注目しているかということを分析し，その情報が対話の流れにどういう影響を及ぼしているかについて，調査・分析を行う．<BR>
これを活用することで，よりユーザの目的に合った対話制御を行えることが期待できる．<BR>
<BR>
<B>・開発した対話システムを用いたコーパス収集</B><BR>
対話システムの応答タイミング・応答種類決定の学習に使うコーパスを，開発した対話システムの環境を用いて収集することを考えている．入力・出力に現在のシステムを用い，応答タイミングと応答選択は，人手でリアルタイムにWOZ形式（人間がシステムの代役をする）で行う．これにより，対話内容と同時に実際のシステムの内部状態も記録することができる．これには，ユーザの発話内容，話速，音声のピッチ・パワー情報，応答タイミング，応答種類や，その他のシステムの内部状況が含まれている．これらの情報を用いて，応答タイミングと応答種類を決定しているモデルの学習を行い調査・分析をすることで，より頑健な応答タイミング・応答種類の選択を学習することが可能になるものと思われる．<BR>
<BR>

</td></tr>
</table>

</center>
</BODY>
</HTML>
